{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452aa55a",
   "metadata": {},
   "source": [
    "## The answer to question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824dc110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Part 1:\n",
    "\n",
    "# number of samples per cluster\n",
    "pts = 50\n",
    "\n",
    "# random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "a = rng.multivariate_normal(\n",
    "    mean=[0,0],\n",
    "    cov=[[0.08,0],\n",
    "         [0,4]],\n",
    "    size=pts,\n",
    ")\n",
    "\n",
    "b = rng.multivariate_normal(\n",
    "    mean=[3,3],\n",
    "    cov=[[4,0],\n",
    "         [0,0.08]],\n",
    "    size=pts,\n",
    ")\n",
    "\n",
    "x = np.concatenate((a, b))\n",
    "\n",
    "# Plot data\n",
    "plt.scatter(x[:, 0], x[:, 1])\n",
    "plt.xlabel(\"x0\")\n",
    "plt.ylabel(\"x1\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae0bf3",
   "metadata": {},
   "source": [
    "## The answer to question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8e74bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# number of samples per cluster\n",
    "pts = 50\n",
    "\n",
    "# random number generator\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "a = rng.multivariate_normal(\n",
    "    mean=[0,0],\n",
    "    cov=[[0.08,0],\n",
    "         [0,4]],\n",
    "    size=pts,\n",
    ")\n",
    "\n",
    "b = rng.multivariate_normal(\n",
    "    mean=[3,3],\n",
    "    cov=[[4,0],\n",
    "         [0,0.08]],\n",
    "    size=pts,\n",
    ")\n",
    "\n",
    "x = np.concatenate((a, b))\n",
    "\n",
    "def kmeans(x, k, no_of_iterations):\n",
    "\n",
    "    \"\"\" Function to implement k-means clustering\n",
    "    # x is a (num_samples, 2) numpy array\n",
    "    # k is number of clusters\n",
    "    # no_of_iterations is the number of iterations to run k means\n",
    "    \"\"\"\n",
    "\n",
    "    # Randomly choose initial Centroids\n",
    "    idx = np.random.choice(len(x), k, replace=False)\n",
    "\n",
    "    centroids = x[idx, :]\n",
    "    distances = cdist(x, centroids ,'euclidean')\n",
    "    points = np.array([np.argmin(i) for i in distances])\n",
    "\n",
    "    # main loop\n",
    "    for _ in range(no_of_iterations):\n",
    "\n",
    "        centroids = []\n",
    "\n",
    "        for idx in range(k):\n",
    "            temp_cent = x[points==idx].mean(axis=0)\n",
    "            centroids.append(temp_cent)\n",
    "        centroids = np.vstack(centroids)\n",
    "        distances = cdist(x, centroids ,'euclidean')\n",
    "        points = np.array([np.argmin(i) for i in distances])\n",
    "\n",
    "    return points\n",
    "\n",
    "# use function\n",
    "points = kmeans(x,k=2,no_of_iterations=10)\n",
    "\n",
    "# assign clusters\n",
    "cluster1 = x[points==0]\n",
    "cluster2 = x[points==1]\n",
    "\n",
    "# Plot the data in labeled clusters\n",
    "plt.scatter(cluster1[:, 0], cluster1[:, 1])\n",
    "plt.scatter(cluster2[:, 0], cluster2[:, 1])\n",
    "plt.xlabel(\"x0\")\n",
    "plt.ylabel(\"x1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e94294",
   "metadata": {},
   "source": [
    "## The answer to question 3 - Part 1 (ZeroR)\n",
    "We analyze the ZeroR on the given dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b061acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data started finished ...\n",
      "Reading data finished ...\n",
      "4310 surprised out of: 84169\n",
      "Correct for ZeroR is: 641  out of: 12078 %5.3071700612684225\n"
     ]
    }
   ],
   "source": [
    "from fileIO import get_file\n",
    "labels = {'sentimental': 0, 'afraid': 1, 'proud': 2, 'faithful': 3, 'terrified': 4, 'joyful': 5,\n",
    "          'angry': 6, 'sad': 7, 'jealous': 8, 'grateful': 9, 'prepared': 10, 'embarrassed': 11, 'excited': 12,\n",
    "          'annoyed': 13, 'lonely': 14, 'ashamed': 15, 'guilty': 16, 'surprised': 17, 'nostalgic': 18,\n",
    "          'confident': 19, 'furious': 20, 'disappointed': 21, 'caring': 22, 'trusting': 23, 'disgusted': 24,\n",
    "          'anticipating': 25, 'anxious': 26, 'hopeful': 27, 'content': 28, 'impressed': 29, 'apprehensive': 30,\n",
    "          'devastated': 31}\n",
    "\n",
    "prompt_train, response_train, labels_train, prompt_val, response_val, labels_val = get_file()\n",
    "D_train = {}\n",
    "\n",
    "max_val = -1\n",
    "max_label = -1\n",
    "for i in labels_train:\n",
    "    if i not in D_train:\n",
    "        D_train[i] = 1\n",
    "    else:\n",
    "        D_train[i] += 1\n",
    "    val = D_train[i]\n",
    "    if val> max_val:\n",
    "        max_val = val\n",
    "        max_label = i\n",
    "\n",
    "print(max_val,max_label,\"out of:\", len(labels_train))\n",
    "acc = 0\n",
    "for i in labels_val:\n",
    "    if max_label == i:\n",
    "        acc+=1\n",
    "print(\"Correct for ZeroR is:\", acc, \" out of:\", len(labels_val), \"%\"+str(acc/len(labels_val)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f269b4",
   "metadata": {},
   "source": [
    "## The answer to question 3 - Part 2 (Main Code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "from FinalSubmission.custom_dataset import tokenizer, Dataset\n",
    "from FinalSubmission.fileIO import get_file\n",
    "from FinalSubmission.gpt2_model import model\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def cross_entropy_loss(logits, target_ids):\n",
    "    \"\"\"\n",
    "    For F.cross_entropy the Input is shape (N, C), where N = batch_size x sequence_length\n",
    "    and C is the number of classes, in our case C is the number of tokens in the vocabulary\n",
    "    Target is shape (N).\n",
    "\n",
    "    https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html\n",
    "\n",
    "    we flatten the batch dimension together with the max_seq length\n",
    "    so that for the loss funstion, so afterwards, there is no batch dimension,\n",
    "    just a vector sized C-dimensions for each of the seq_len tokens.\n",
    "    If there had been 2 sampels with a batch size of 2, with 3 tokens in each sample\n",
    "    then the predictions.shape would be torch.Size([6, 50257])\n",
    "\n",
    "    Args:\n",
    "        logits (torch.tensor, float): shape [batch_size, sequence_length, vocab_size]\n",
    "        target_ids (torch.tensor, int): shape [batch_size, sequence_length]\n",
    "\n",
    "    Returns:\n",
    "        scalar_loss (torch.tensor, scalar float, grad_fn=<NllLossBackward0>)): no shape\n",
    "            this is a loss you can backpropagate using:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scalar_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = logits.view(-1, logits.size(-1))\n",
    "    target = target_ids.view(-1)\n",
    "\n",
    "    scalar_loss = F.cross_entropy(\n",
    "        predictions,\n",
    "        target,\n",
    "    )\n",
    "\n",
    "    return scalar_loss\n",
    "\n",
    "\n",
    "class BaseAgent(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, tokenizer, model, device=-1):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.98), eps=1e-9,)\n",
    "\n",
    "        self.num_gpus = torch.cuda.device_count()\n",
    "        \"\"\"\n",
    "        if self.num_gpus > 1:\n",
    "            self.model.parallelize()\n",
    "        elif self.num_gpus == 1:\n",
    "            self.model = self.model.cuda()\"\"\"\n",
    "        #for plots\n",
    "        self.x_epoch = []\n",
    "        self.y_loss = {\"train\":[],\"val\":[]}\n",
    "        self.y_acc = {\"val\":[],\"SentCompletion\":[]}\n",
    "\n",
    "        # handle GPU better\n",
    "        if device == -1:\n",
    "            use_cuda = torch.cuda.is_available()\n",
    "            self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        self.model = self.model.to(self.device )#.cuda()\n",
    "\n",
    "\n",
    "    def draw_curve(self, current_epoch):\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig = plt.figure()\n",
    "        ax0 = fig.add_subplot(121, title=\"loss\")\n",
    "        ax1 = fig.add_subplot(122, title=\"accuracy\")\n",
    "\n",
    "        ax0.plot(self.x_epoch, self.y_loss['train'], 'bo-', label='train')\n",
    "        ax0.plot(self.x_epoch, self.y_loss['val'], 'ro-', label='val')\n",
    "        ax1.plot(self.x_epoch, self.y_acc['val'], 'bo-', label='val')\n",
    "        ax1.plot(self.x_epoch, self.y_acc['SentCompletion'], 'ro-', label='val snt compl')\n",
    "        ax0.legend(loc=\"upper left\")\n",
    "        ax1.legend(loc=\"upper left\")\n",
    "        fig.savefig(os.path.join('./plots', str(current_epoch)+'_plot.png'))\n",
    "\n",
    "    def get_response(self, prompt, max_len = 32):\n",
    "\n",
    "        prompt_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\",)\n",
    "\n",
    "        if self.num_gpus > 0:\n",
    "            prompt_ids = prompt_ids.to(self.device)#.cuda()\n",
    "\n",
    "        prompt_len = prompt_ids.shape[1]\n",
    "\n",
    "        output_ids = self.model.generate(prompt_ids, max_length=prompt_len+max_len, )\n",
    "\n",
    "        generated_text = self.tokenizer.batch_decode(output_ids)[0]\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "    def memorize(self, prompt_train, response_train, labels_train, prompt_val, response_val, labels_val, epochs, batch_size):\n",
    "        train, val = Dataset(prompt_train, response_train, labels_train), Dataset(prompt_val, response_val, labels_val)\n",
    "\n",
    "        train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\n",
    "\n",
    "        # allow params to be updated\n",
    "        best_acc = -1\n",
    "        self.model.train()\n",
    "        for epoch_num in range(epochs):\n",
    "            total_train_samples = 0\n",
    "            total_loss_train = 0\n",
    "            print(\"epoch\", epoch_num)\n",
    "            for train_input, train_label in tqdm(train_dataloader):#We dont use labels here, it was constructed on dataset itself\n",
    "                prompt = \"\"\n",
    "                for str in train_input:\n",
    "                    total_train_samples += 1\n",
    "                    prompt += str\n",
    "                #print(prompt)\n",
    "                prompt_dic = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "                prompt_ids = prompt_dic.input_ids\n",
    "                prompt_mask = prompt_dic.attention_mask\n",
    "                prompt_len = prompt_ids.shape[1]\n",
    "\n",
    "                if self.num_gpus > 0:\n",
    "                    prompt_ids = prompt_ids.to(self.device)#.cuda()\n",
    "                    prompt_mask = prompt_mask.to(self.device)#.cuda()\n",
    "\n",
    "                source_ids = prompt_ids[:, :-1]\n",
    "                target_ids = prompt_ids[:, 1:]\n",
    "                source_mask = prompt_mask[:, :-1]\n",
    "                target_mask = prompt_mask[:, 1:]\n",
    "\n",
    "                output = self.model(input_ids=source_ids, attention_mask=source_mask,)\n",
    "\n",
    "                # used logits and target tokens to calculate the loss\n",
    "                logits = output.logits\n",
    "\n",
    "                scalar_loss = cross_entropy_loss(logits, target_ids,)\n",
    "                total_loss_train += scalar_loss.item()\n",
    "\n",
    "                # backward pass\n",
    "                self.optimizer.zero_grad()\n",
    "                scalar_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            total_val_samples = 0\n",
    "            total_complete_sentences = 0\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_input, val_label in val_dataloader:\n",
    "                    prompt = \"\"\n",
    "                    for stri in val_input:\n",
    "                        original_A = stri.split(\"B: \")[0]\n",
    "                        original_B = stri.split(\"B: \")[1]\n",
    "                        original_lbl = original_B.split(\"<EMOTION_TYPE> \")[1]\n",
    "                        original_lbl = original_lbl.split(\" <|endoftext|>\")[0]\n",
    "                        predict_B = self.get_response(original_A+\"B: \", max_len = 52)\n",
    "                        predict_lbl = predict_B.split(\"<EMOTION_TYPE> \")\n",
    "                        if len(predict_lbl)>1:\n",
    "                            predict_lbl = predict_lbl[1]\n",
    "                            predict_lbl = predict_lbl.split(\" <|endoftext|>\")\n",
    "                            if len(predict_lbl)>1:\n",
    "                                predict_lbl = predict_lbl[0]\n",
    "                                total_complete_sentences += 1\n",
    "                                if predict_lbl == original_lbl:\n",
    "                                    total_acc_val += 1\n",
    "                        #print(original_A, original_B, predict_B,\"\\n\",original_lbl,predict_lbl)\n",
    "                        total_val_samples += 1\n",
    "                        prompt += stri\n",
    "                    prompt_dic = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "                    prompt_ids = prompt_dic.input_ids\n",
    "                    prompt_mask = prompt_dic.attention_mask\n",
    "                    prompt_len = prompt_ids.shape[1]\n",
    "\n",
    "                    if self.num_gpus > 0:\n",
    "                        prompt_ids = prompt_ids.to(self.device)#.cuda()\n",
    "                        prompt_mask = prompt_mask.to(self.device)#.cuda()\n",
    "\n",
    "                    source_ids = prompt_ids[:, :-1]\n",
    "                    target_ids = prompt_ids[:, 1:]\n",
    "                    source_mask = prompt_mask[:, :-1]\n",
    "                    target_mask = prompt_mask[:, 1:]\n",
    "\n",
    "                    output = self.model(input_ids=source_ids, attention_mask=source_mask,)\n",
    "\n",
    "                    # used logits and target tokens to calculate the loss\n",
    "                    logits = output.logits\n",
    "\n",
    "                    scalar_loss = cross_entropy_loss(logits, target_ids,)\n",
    "\n",
    "                    total_loss_val += scalar_loss.item()\n",
    "                    print(\"total_loss_val\",total_loss_val)\n",
    "\n",
    "            if total_complete_sentences == 0:\n",
    "                total_complete_sentences = 1\n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / total_train_samples: .3f} \\\n",
    "                        | Val Loss: {total_loss_val / total_val_samples: .3f} \\\n",
    "                        | Total val complete sentences: {total_complete_sentences: .3f} \\\n",
    "                        | Total val samples: {total_val_samples: .3f} \\\n",
    "                        | Val Loss: {total_loss_val / total_val_samples: .3f} \\\n",
    "                        | Val Accuracy: {total_acc_val / total_complete_sentences: .3f}')\n",
    "            #if only save the best, take out the comment\n",
    "            if True:#best_acc < total_acc_val / total_complete_sentences:\n",
    "                best_acc = total_acc_val / total_complete_sentences\n",
    "                print(\"Saving the model on epoch\", epoch_num, \"best accuracy is:\", best_acc)\n",
    "                torch.save(model.state_dict(), \"gpt2_model.pth\")\n",
    "            #this is for the plots\n",
    "            self.x_epoch.append(epoch_num)\n",
    "            self.y_loss[\"train\"].append(total_loss_train / total_train_samples)\n",
    "            self.y_loss[\"val\"].append(total_loss_val / total_val_samples)\n",
    "            self.y_acc[\"val\"].append(total_acc_val / total_complete_sentences)\n",
    "            self.y_acc[\"SentCompletion\"].append(total_complete_sentences)\n",
    "            if epoch_num%10==0:\n",
    "                self.draw_curve(epoch_num)\n",
    "        self.draw_curve(epochs-1)\n",
    "\n",
    "#to train take out the comment out to run the server puy them in comment\n",
    "\"\"\"\n",
    "ba = BaseAgent(tokenizer, model,device = 2)\n",
    "prompt_train, response_train, labels_train, prompt_val, response_val, labels_val = get_file(2000,200)\n",
    "ba.memorize(prompt_train, response_train, labels_train, prompt_val, response_val, labels_val,100, 10)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7f43a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70be9a",
   "metadata": {},
   "source": [
    "The code provides two types of metrics the 'loss' is for normal train and validation loss. The accuracy provides two metrics one is how many sentences are completed and the other if those sentences had the same sentiment. Because I didnt have time to complete the training on all data the second type is not that much but the sentence accuracy goes as expected.\n",
    "\n",
    "Epoch 0\n",
    "![0_plot](plots/0_plot.png)\n",
    "Epoch 10\n",
    "![10_plot](plots/10_plot.png)\n",
    "Epoch 20\n",
    "![20_plot](plots/20_plot.png)\n",
    "Epoch 30\n",
    "![30_plot](plots/30_plot.png)\n",
    "Epoch 40\n",
    "![40_plot](plots/40_plot.png)\n",
    "Epoch 50\n",
    "![50_plot](plots/50_plot.png)\n",
    "Epoch 60\n",
    "![60_plot](plots/60_plot.png)\n",
    "Epoch 70\n",
    "![70_plot](plots/70_plot.png)\n",
    "Epoch 80\n",
    "![80_plot](plots/80_plot.png)\n",
    "Epoch 90\n",
    "![90_plot](plots/90_plot.png)\n",
    "Epoch 99\n",
    "![99_plot](plots/99_plot.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2db30",
   "metadata": {},
   "source": [
    "## Extra credit - Creating a client-server chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "\n",
    "\n",
    "# load the model once\n",
    "from FinalSubmission.Part3_main import BaseAgent\n",
    "from FinalSubmission.custom_dataset import tokenizer\n",
    "from FinalSubmission.gpt2_model import model\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"gpt2_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "ba = BaseAgent(tokenizer, model,device = 2)\n",
    "\n",
    "def run_test(text):\n",
    "    predict_B = ba.get_response(\"A: \"+ text + \"B: \", max_len=52)\n",
    "    predict_lbl = predict_B.split(\"B: \")\n",
    "    if len(predict_lbl)>1:\n",
    "        predict_lbl = predict_lbl[1]\n",
    "        predict_lbl = predict_lbl.split(\"<EMOTION_TYPE> \")\n",
    "        if len(predict_lbl)>1:\n",
    "            predict_lbl = predict_lbl[0]\n",
    "    predict_lbl = \"\".join(predict_lbl)\n",
    "    result = predict_lbl\n",
    "    return result\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "cors = CORS(app)\n",
    "\n",
    "\n",
    "# Create the receiver API POST endpoint:\n",
    "@app.route(\"/receiver\", methods=[\"POST\"])\n",
    "def postME():\n",
    "    # get the data from client, run it through NN classifier, return the result in a json file to client\n",
    "    data = request.get_json()\n",
    "    data = run_test(json.dumps(data))\n",
    "    data = jsonify(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b236387",
   "metadata": {},
   "source": [
    "The html client can connect to the server. This shows that bot (julia) answers correctly to the sentiment.\n",
    "![title](plots/img.png)\n",
    "Following is the html file for the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6acf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "    <title>\n",
    "        Chatbot\n",
    "    </title>\n",
    "</head>\n",
    "\n",
    "<body style=\"text-align:center;\">\n",
    "\n",
    "    <h1 style=\"color:green;\">\n",
    "        Welcome!\n",
    "    </h1>\n",
    "\n",
    "    <h4>\n",
    "         input text:\n",
    "    </h4>\n",
    "\n",
    "    <textarea id = \"input_sequence\" name = \"sequence\" rows = \"6\" cols = \"40\" style=\"border:solid 1px black;\"></textarea>\n",
    "\n",
    "    <br>\n",
    "\n",
    "    <label id = \"LBL\">\n",
    "        Click the Button\n",
    "    </label>\n",
    "\n",
    "    <br>\n",
    "\n",
    "    <button onclick=\"getLabel()\">\n",
    "        Click Here!\n",
    "    </button>\n",
    "\n",
    "    <script>\n",
    "        function getLabel() {\n",
    "            document.getElementById('LBL').innerHTML  = 'Wait for 60 seconds ...';\n",
    "            fetch(\"http://127.0.0.1:5000/receiver\",\n",
    "        {\n",
    "            method: 'POST',\n",
    "            headers: {\n",
    "                'Content-type': 'application/json',\n",
    "                'Accept': 'application/json'\n",
    "            },\n",
    "        // Strigify the payload into JSON:\n",
    "        body:JSON.stringify(document.getElementById(\"input_sequence\").value)}).then(res=>{\n",
    "                if(res.ok){\n",
    "                    return res.json()\n",
    "                }else{\n",
    "                    alert(\"something is wrong\")\n",
    "                }\n",
    "            }).then(jsonResponse=>{\n",
    "\n",
    "                document.getElementById('LBL').innerHTML  = 'Julia: ' + jsonResponse;\n",
    "                console.log(jsonResponse)\n",
    "            }\n",
    "            ).catch((err) => console.error(err));\n",
    "\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "\n",
    "</html>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
